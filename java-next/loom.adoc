== Project Loom
image::images/loom.jpg[background, size=cover]

> Fibers, delimited continuations, explicit tail-call

Profile:

* led by Ron Pressler
* http://openjdk.java.net/projects/loom/[project] /
https://wiki.openjdk.java.net/display/loom/Main[wiki] /
http://mail.openjdk.java.net/mailman/listinfo/loom-dev[mailing list] /
talks:
https://www.youtube.com/watch?v=fpyub8fbrVE[0],
https://www.youtube.com/watch?v=J31o0ZMQEnI[1],
https://www.youtube.com/watch?v=NV46KFV1m-4[2] / +
http://jdk.java.net/loom[official early access builds]
* launched January 2018

=== Motivation

Imagine a hypothetical request:

. interpret request
. query database (_blocks_)
. process data for response

JVM resource utilization:

* good for tasks 1., 3.
* really bad for task 2.

How to implement that request?

=== Motivation

Synchronous (simple)::
* thread per request
* blocks on certain calls
* bad thread utilization
Asynchronous (not so simple)::
* use non-blocking APIs with futures
* incompatible with synchronous code
* great thread utilization (scalable!)

[NOTE.speaker]
--
* common CPU load: 5-30%
--

=== Enter fibers!

A fiber:

* looks like a thread to devs
* low memory footprint ([k]bytes)
* small switching cost
* *scheduled by the JVM*

=== Fiber management

The JVM manages fibers:

* runs them in a pool of _carrier threads_
* makes fibers _yield_ on blocking calls +
(*frees the carrier thread!*)
* _continues_ fibers when calls return

=== Fiber example

Remember the hypothetical request:

. interpret request
. query database (_blocks_)
. process data for response

In a fiber:

[%step]
* JVM submits fiber to thread pool
* when 2. blocks, fiber yields
* JVM hands thread back to pool +
* when 2. unblocks, JVM resubmits fiber
* fiber continues with 3. (how?)

=== Fibers

*Yeah:*

* great thread utilization
* code is written/debugged as if synchronous
* legacy code _may_ be forward compatible

=== Continuations

How do fibers _continue_?

* use continuations (low-level API)
* JVM stores and restores call stack

=== Project Loom

Makes threading more pleasant:

* simple programming model
* great thread utilization
