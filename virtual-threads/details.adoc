== Scaling Simply

{toc}

=== Preparing your code

Virtual threads:

* always work correctly
* may not scale perfectly

Code changes can improve scalability +
(and maintainability, debuggability, observability).

=== Avoid thread pools

Only pool expensive resources +
but virtual threads are cheap.

‚áù Replace thread pools (for concurrency), +
  with virtual threads plus, e.g., semaphores.

=== With thread pools

```java
// limits concurrent queries but pools üëéüèæ
private static final ExecutorService DB_POOL =
	Executors.newFixedThreadPool(16);

public <T> Future<T> queryDatabase(Callable<T> query) {
	return DB_POOL.submit(query);
}
```

=== With semaphore

```java
// limits concurrent queries without pool üëçüèæ
private static final Semaphore DB_SEMAPHORE =
	new Semaphore(16);

public <T> T queryDatabase(Callable<T> query)
		throws Exception {
	DB_SEMAPHORE.acquire();
	try {
		return query.call();
	} finally {
		DB_SEMAPHORE.release();
	}
}
```

=== Caveats

To understand virtual thread caveats +
we need to understand how they work.

(Also, it's very interesting.)

=== Under the hood

The Java runtime manages virtual threads:

[%step]
* runs them on a pool of _carrier threads_ +
* on blocking call:
[%step]
** internally calls non-blocking operation
** *_unmounts_ from carrier thread!*
* when call returns: +
[%step]
** _mounts_ to (other) carrier thread
** continues

[NOTE.speaker]
--
* dedicated `ForkJoinPool` in FIFO mode
--

=== Stack chunks

A virtual thread stack:

* when waiting, is stored on heap (_stack chunk objects_)
* when continuing, is lazily streamed to stack

This keeps switching cheap.

=== The simple web request

Remember the hypothetical request:

. interpret request
. query database (_blocks_)
. process data for response

In a virtual thread:

[%step]
* runtime submits task to carrier thread pool
* when 2. blocks, virtual thread unmounts
* runtime hands carrier thread back to pool
* when 2. unblocks, runtime resubmits task
* virtual thread mounts and continues with 3.

=== Configuration

Carrier thread pool size +
can be configured:

`-Djdk.virtualThreadScheduler.maxPoolSize=...`

Let's measure `Thread::sleep` again:

* remember that this is a pointless benchmark
* executed on a laptop!

=== "Benchmark"

Carrier (rows) vs virtual (columns) threads:

[cols="2,1,1,1,1,1"]
|===
|                 |   1k |  10k | 100k | 500k |  1m
| 1               | 1.0s | 1.1s | 1.7s |   6s | 12s
| 2               | 1.0s | 1.1s | 1.5s |   4s |  9s
| 4 (CPU cores)   | 1.0s | 1.1s | 1.3s |   3s |  6s
| 8 (CPU threads) | 1.0s | 1.1s | 1.3s |   3s |  6s
| 16+             | 1.0s | 1.1s | 1.3s |   3s |  6s
|===

=== Compatibility

Virtual threads work correctly with everything:

* all blocking operations
* `synchronized`
* `Thread`, `currentThread`, etc.
* thread interruption
* thread-locals
* native code

But not all scale perfectly.

// TODO: explain JFR events to discover issues

=== Caveat #1: capture

Despite lots of internal rework
(e.g. JEPs https://openjdk.org/jeps/353[353], https://openjdk.org/jeps/373[373]) +
not all blocking operations unmount.

Some _capture_ platform thread:

* `Object::wait`
* file I/O (‚áù _io_uring_)

‚áù Compensated by temporarily growing carrier pool.

‚ö†Ô∏è Problematic when capturing operations dominate.

=== Caveat #2: pinning

Some operations _pin_ (operations don't unmount):

* native method call (JNI)
* foreign function call (FFM)
* `synchronized` block (for now)

‚áù No compensation

‚ö†Ô∏è Problematic when:

* pinning is frequent
* contains blocking operations


=== Avoid long-running pins

If possible:

* avoid pinning operations
* remove blocking operations +
  from pinning code sections.

=== With synchronization

```java
// guarantees sequential access, but pins (for now) üëéüèæ
public synchronized String accessResource() {
	return access();
}
```

=== With lock

```java
// guarantees sequential access without pinning üëçüèæ
private static final ReentrantLock LOCK =
	new ReentrantLock();

public String accessResource() {
	// lock guarantees sequential access
	LOCK.lock();
	try {
		return access();
	} finally {
		LOCK.unlock();
	}
}
```

=== Caveat #3: thread locals

Thread-locals can hinder scalability:

* can be inherited
* to keep them thread-local, +
  values are copied
* can occupy lots of memory

(There are also API shortcomings.)

‚áù Refactor to scoped values (https://openjdk.org/jeps/446[JEP 446]).

=== With thread-local

```java
// copies value for each inheriting thread üëéüèæ
static final ThreadLocal<Principal> PRINCIPAL =
	new ThreadLocal<>();

public void serve(Request request, Response response) {
	var level = request.isAdmin() ? ADMIN : GUEST;
	var principal = new Principal(level);
	PRINCIPAL.set(principal);
	Application.handle(request, response);
}
```

=== With scoped value

```java
// immutable, so no copies needed üëçüèæ
static final ScopedValue<Principal> PRINCIPAL =
	new ScopedValue<>();

public void serve(Request request, Response response) {
	var level = request.isAdmin() ? ADMIN : GUEST;
	var principal = new Principal(level);
	ScopedValue
		.where(PRINCIPAL, principal)
		.run(() -> Application
			.handle(request, response));
}
```

=== Preparing your code:

Most importantly:

. replace thread pools with semaphores

Also helpful:

[start=2]
. remove long-running I/O from pinned sections
. replace thread-locals with scoped values
. replace `synchronized` with locks
